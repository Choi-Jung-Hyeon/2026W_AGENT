import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import os

# [ì„¤ì •] .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ (ë³´ì•ˆì„ ìœ„í•´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
load_dotenv("key.env")

# [ì„¤ì •] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI()

# [UI] ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª© ì„¤ì •
st.title("ğŸ¤– ë‚˜ë§Œì˜ AI ì±—ë´‡")

# [ë¡œì§] 4. ì„¸ì…˜ ìƒíƒœ(session_state)ë¥¼ í™œìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ ìœ ì§€
# 'messages'ë¼ëŠ” í‚¤ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
if "messages" not in st.session_state:
    st.session_state.messages = []

# [UI] ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
# ì„¸ì…˜ì— ì €ì¥ëœ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ìˆœì„œëŒ€ë¡œ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# [UI/ë¡œì§] 1. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° (chat_input ì‚¬ìš©)
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©ì„ í™”ë©´ì— í‘œì‹œ
    with st.chat_message("user"):
        st.write(prompt)
    
    # ëŒ€í™” ê¸°ë¡(ì„¸ì…˜)ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})

    # [ë¡œì§] 2. OpenAI APIë¡œ ì§ˆë¬¸ ì „ë‹¬ ë° ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                # 3. ëª¨ë¸ì˜ ì‘ë‹µì„ ë°›ì•„ì˜´ (ì „ì²´ ëŒ€í™” ê¸°ë¡ ì „ë‹¬í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€)
                response = client.chat.completions.create(
                    model="gpt-4o",  # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ëª… (gpt-3.5-turbo ë“±)
                    messages=st.session_state.messages
                )
                assistant_response = response.choices[0].message.content
                st.write(assistant_response)
                
                # [ë¡œì§] ëŒ€í™” ê¸°ë¡(ì„¸ì…˜)ì— AI ì‘ë‹µ ì¶”ê°€
                st.session_state.messages.append({"role": "assistant", "content": assistant_response})
            except Exception as e:
                st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")