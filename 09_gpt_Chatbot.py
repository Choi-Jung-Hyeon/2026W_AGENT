import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import os

# [ìˆ˜ì •] ê°•ì‚¬ë‹˜ ì½”ë“œëŠ” .envì§€ë§Œ, ì‚¬ìš©ìë‹˜ì€ key.envë¥¼ ì“°ì‹œë¯€ë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
load_dotenv("key.env")
client = OpenAI()

# Streamlit ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ rerun í•¨ìˆ˜
def safe_rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    elif hasattr(st, "experimental_rerun"):
        st.experimental_rerun()
    else:
        st.warning("í˜„ì¬ Streamlit ë²„ì „ì—ì„œ rerun í•¨ìˆ˜ê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# LLM í˜¸ì¶œ í•¨ìˆ˜ (ìµœì‹  Responses API ì‚¬ìš©)
def chatbot(messages, temperature=0.7, max_tokens=1000, model="gpt-4.1-mini"):
    try:
        # [ìµœì‹  ë¬¸ë²•] client.responses.create ì‚¬ìš©
        response = client.responses.create(
            model=model,
            input=messages,           # messages -> input
            temperature=temperature,
            max_output_tokens=max_tokens # max_tokens -> max_output_tokens
        )
        return response.output_text.strip() # content -> output_text

    except Exception as e:
        return f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"

# -------------------------------------------------------------------
# Streamlit UI ì„¤ì •
# -------------------------------------------------------------------

# 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (íƒ­ ì œëª©, ì•„ì´ì½˜)
st.set_page_config(page_title="ë‚˜ë§Œì˜ GPT ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ğŸ¤– GPT ì±—ë´‡ (Responses API)")

# 2. ì‚¬ì´ë“œë°” ì„¤ì • (ì˜µì…˜ ì¡°ì ˆ)
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ëª¨ë¸ ì„ íƒ (gpt-4.1-mini ê¸°ë³¸)
    model = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        ["gpt-4.1-mini", "gpt-4o", "gpt-3.5-turbo"],
        index=0
    )

    # Temperature ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    temperature = st.slider(
        "Temperature (ì°½ì˜ì„±)",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="ê°’ì´ ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ë‹µë³€ì„ í•©ë‹ˆë‹¤."
    )

    st.divider()

    # ğŸ”„ ëŒ€í™” ë‹¤ì‹œ ì‹œì‘ ë²„íŠ¼
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = [
            {
                "role": "developer",
                "content": "You are a helpful assistant. Respond in Korean."
            }
        ]
        safe_rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨

# 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ì €ì¥ì†Œ)
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "developer",
            "content": "You are a helpful assistant. Respond in Korean."
        }
    ]

# 4. ì´ì „ ëŒ€í™” ë‚´ìš© í™”ë©´ì— ì¶œë ¥
for msg in st.session_state.messages:
    # ì‹œìŠ¤í…œ(developer) ë©”ì‹œì§€ëŠ” í™”ë©´ì— ì•ˆ ë³´ì—¬ì¤Œ
    if msg["role"] == "developer":
        continue
    
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

if user_input:
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ê³  ì €ì¥
    with st.chat_message("user"):
        st.markdown(user_input)
    
    st.session_state.messages.append(
        {"role": "user", "content": user_input}
    )

    # (2) GPT ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        with st.spinner("ìƒê°í•˜ëŠ” ì¤‘..."):
            answer = chatbot(
                messages=st.session_state.messages,
                temperature=temperature,
                model=model
            )
            st.markdown(answer)

    # (3) GPT ì‘ë‹µ ì €ì¥
    st.session_state.messages.append(
        {"role": "assistant", "content": answer}
    )