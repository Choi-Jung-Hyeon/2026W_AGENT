{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d4bee7",
   "metadata": {},
   "source": [
    "## **STEP1. ë­ì²´ì¸ìœ¼ë¡œ GPT ë¶€ë¥´ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482e9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb789b1",
   "metadata": {},
   "source": [
    "ğŸ“Œ í•µì‹¬ ê°œë…:\n",
    "- PromptTemplate: ë³€ìˆ˜ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "- system ë©”ì‹œì§€: AIì˜ ì—­í• /ì„±ê²© ì§€ì •\n",
    "- human ë©”ì‹œì§€: ì‚¬ìš©ìì˜ ì‹¤ì œ ì…ë ¥\n",
    "- í…œí”Œë¦¿ì„ ì“°ë©´ í”„ë¡¬í”„íŠ¸ ì¬ì‚¬ìš©ì´ ì‰¬ì›Œì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de2a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¢‹ì€ ì§ˆë¬¸ì´ì•¼! ì–‘ìì—­í•™ì€ ì•„ì£¼ì•„ì£¼ ì‘ì€ ì„¸ìƒ, ì˜ˆë¥¼ ë“¤ì–´ ì›ìë‚˜ ì „ìì²˜ëŸ¼ ëˆˆì— ë³´ì´ì§€ ì•ŠëŠ” ì‘ì€ ì…ìë“¤ì´ ì–´ë–»ê²Œ ì›€ì§ì´ê³  í–‰ë™í•˜ëŠ”ì§€ë¥¼ ì—°êµ¬í•˜ëŠ” ê³¼í•™ì´ì•¼.\n",
      "\n",
      "ìš°ë¦¬ê°€ ì¼ìƒì—ì„œ ë³´ëŠ” í° ë¬¼ê±´ë“¤ì€ ë³´í†µ ë‰´í„´ì˜ ë²•ì¹™ìœ¼ë¡œ ì˜ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ë°, ì•„ì£¼ ì‘ì€ ì„¸ê³„ì—ì„œëŠ” ê·¸ ë²•ì¹™ë“¤ì´ ì˜ ë§ì§€ ì•Šì•„. ê·¸ë˜ì„œ ê³¼í•™ìë“¤ì´ ìƒˆë¡­ê²Œ ë§Œë“  ë²•ì´ ë°”ë¡œ ì–‘ìì—­í•™ì´ì•¼.\n",
      "\n",
      "ì–‘ìì—­í•™ì—ì„œëŠ” ì‘ì€ ì…ìë“¤ì´ ë§ˆì¹˜ íŒŒë„ì²˜ëŸ¼ ì›€ì§ì´ê¸°ë„ í•˜ê³ , ë™ì‹œì— ì—¬ëŸ¬ ê³³ì— ìˆì„ ìˆ˜ë„ ìˆì–´. ê·¸ë¦¬ê³  ìš°ë¦¬ê°€ ê·¸ ì…ìë¥¼ ê´€ì°°í•˜ë©´ ê·¸ë•Œì„œì•¼ ìœ„ì¹˜ê°€ í™•ì‹¤í•´ì§„ë‹¨ë‹¤.\n",
      "\n",
      "ì‰½ê²Œ ë§í•˜ë©´, ì–‘ìì—­í•™ì€ ì•„ì£¼ ì‘ì€ ì„¸ê³„ì˜ ì‹ ê¸°í•œ ê·œì¹™ë“¤ì„ ì•Œë ¤ì£¼ëŠ” ê³¼í•™ì´ë¼ê³  ìƒê°í•˜ë©´ ë¼!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"key.env\")\n",
    "\n",
    "llm=ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"),\n",
    "    (\"user\", \"{question}\"),\n",
    "])\n",
    "\n",
    "#promptì™€ llmì„ íŒŒì´í”„ë¡œ ì—°ê²°\n",
    "chain = prompt | llm\n",
    "\n",
    "#llm ë‹¨ë…í˜¸ì¶œ\n",
    "response = chain.invoke(\"ì–‘ìì—­í•™ì´ ë­ì•¼?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab89aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in ./venv/lib/python3.12/site-packages (4.2.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./venv/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in ./venv/lib/python3.12/site-packages (from langchain-google-genai) (1.62.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.5 in ./venv/lib/python3.12/site-packages (from langchain-google-genai) (1.2.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in ./venv/lib/python3.12/site-packages (from langchain-google-genai) (2.12.5)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in ./venv/lib/python3.12/site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.48.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (9.1.4)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.15.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in ./venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (46.0.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.7.1)\n",
      "Requirement already satisfied: packaging>=23.2.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (26.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.6.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./venv/lib/python3.12/site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44d4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43edd9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI & Gemini API Key ì„¤ì • ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# Gemini API Key\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Gemini API Key: \")\n",
    "\n",
    "print(\"âœ… OpenAI & Gemini API Key ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07df77fb",
   "metadata": {},
   "source": [
    "| íŒ¨í‚¤ì§€                   | ì—­í•                                        |\n",
    "| --------------------- | ---------------------------------------- |\n",
    "| langchain-core      | **í•µì‹¬ ì¶”ìƒ ê°œë… (Prompt, Runnable, Message)** |\n",
    "| langchain           | ì²´ì¸, ë©”ëª¨ë¦¬, ì—ì´ì „íŠ¸ êµ¬í˜„                         |\n",
    "| langchain-openai    | OpenAI ì—°ë™                                |\n",
    "| langchain-community | ì„œë“œíŒŒí‹° ë„êµ¬                                  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e09fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•!\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"ì•ˆë…•?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd271f31",
   "metadata": {},
   "source": [
    "## **Step 2: ë©”ëª¨ë¦¬ ê´€ë¦¬ (ëŒ€í™” ê¸°ë¡)**\n",
    "\n",
    "[í•µì‹¬ ê°œë…]\n",
    "- ChatMessageHistory: ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤\n",
    "- RunnableWithMessageHistory: ë©”ëª¨ë¦¬ë¥¼ í¬í•¨í•œ ì²´ì¸\n",
    "- session_id: ëŒ€í™” ì„¸ì…˜ì„ êµ¬ë¶„í•˜ëŠ” ID\n",
    "- store: ì—¬ëŸ¬ ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f59c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d17b4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\")\n",
    "\n",
    "#2. prompt (historyë¥¼ ë¼ì›Œ ë„£ëŠ” ê²ƒì´ í•µì‹¬)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "#3. ì„¸ì…˜ë³„ ëŒ€í™” ì €ì¥ì†Œ\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "#4. chain\n",
    "chain = prompt | llm\n",
    "\n",
    "#5. memoryë¥¼ ì²´ì¸ì— ì—°ê²°\n",
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_variable_name=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aeac91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì„¸ì…˜1 ì‹œì‘ ===\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”, ì² ìˆ˜ë‹˜! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "AI: ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì² ìˆ˜ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "\n",
      "=== ì„¸ì…˜2 ì‹œì‘ (ë‹¤ë¥¸ ì„¸ì…˜) ===\n",
      "AI: ì£„ì†¡í•˜ì§€ë§Œ ì´ì „ì— ë‹¹ì‹ ì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹  ì ì´ ì—†ì–´ì„œ ê¸°ì–µí•˜ì§€ ëª»í•´ìš”. ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí• ê²Œìš”!\n",
      "\n",
      "ê²°ê³¼: ì„¸ì…˜2ëŠ” ì„¸ì…˜1ì˜ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•¨\n",
      "\n",
      "=== ì„¸ì…˜1ë¡œ ë³µê·€ ===\n",
      "AI: ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì² ìˆ˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "ê²°ê³¼: ì„¸ì…˜1ì€ ì—¬ì „íˆ 'ì² ìˆ˜'ë¥¼ ê¸°ì–µí•¨\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ëŠ” AIì…ë‹ˆë‹¤.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# ì„¸ì…˜1: ì²« ë²ˆì§¸ ëŒ€í™”\n",
    "print(\"=== ì„¸ì…˜1 ì‹œì‘ ===\")\n",
    "config1 = {\"configurable\": {\"session_id\": \"session1\"}}\n",
    "\n",
    "r1 = chain_with_memory.invoke({\"input\": \"ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼\"}, config=config1)\n",
    "print(f\"AI: {r1.content}\")\n",
    "\n",
    "r2 = chain_with_memory.invoke({\"input\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"}, config=config1)\n",
    "print(f\"AI: {r2.content}\")\n",
    "\n",
    "# ì„¸ì…˜2: ìƒˆë¡œìš´ ëŒ€í™” (ì´ì „ ë‚´ìš© ê¸°ì–µ ëª»í•¨)\n",
    "print(\"\\n=== ì„¸ì…˜2 ì‹œì‘ (ë‹¤ë¥¸ ì„¸ì…˜) ===\")\n",
    "config2 = {\"configurable\": {\"session_id\": \"session2\"}}\n",
    "\n",
    "r3 = chain_with_memory.invoke({\"input\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"}, config=config2)\n",
    "print(f\"AI: {r3.content}\")\n",
    "print(\"\\nê²°ê³¼: ì„¸ì…˜2ëŠ” ì„¸ì…˜1ì˜ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•¨\")\n",
    "\n",
    "# ë‹¤ì‹œ ì„¸ì…˜1ë¡œ ëŒì•„ê°€ë©´ ê¸°ì–µí•¨\n",
    "print(\"\\n=== ì„¸ì…˜1ë¡œ ë³µê·€ ===\")\n",
    "r4 = chain_with_memory.invoke({\"input\": \"ë‚´ ì´ë¦„ ë‹¤ì‹œ ë§í•´ì¤˜\"}, config=config1)\n",
    "print(f\"AI: {r4.content}\")\n",
    "print(\"\\nê²°ê³¼: ì„¸ì…˜1ì€ ì—¬ì „íˆ 'ì² ìˆ˜'ë¥¼ ê¸°ì–µí•¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad52254",
   "metadata": {},
   "source": [
    "# Step 3: Tool ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "049f6abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT ë‹µë³€: `todos.txt` íŒŒì¼ì— 'íŒŒì´ì¬ ê³µë¶€'ë¥¼ ì¶”ê°€í•˜ë ¤ë©´, ë‹¤ìŒê³¼ ê°™ì´ í•˜ë©´ ë©ë‹ˆë‹¤:\n",
      "\n",
      "```python\n",
      "with open('todos.txt', 'a', encoding='utf-8') as file:\n",
      "    file.write('íŒŒì´ì¬ ê³µë¶€\\n')\n",
      "```\n",
      "\n",
      "ì´ ì½”ë“œëŠ” `todos.txt` íŒŒì¼ì„ ì—´ì–´ì„œ(ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“¤ê³ ), íŒŒì¼ ëì— 'íŒŒì´ì¬ ê³µë¶€'ë¼ëŠ” ë¬¸ì¥ì„ í•œ ì¤„ ì¶”ê°€í•©ë‹ˆë‹¤. `encoding='utf-8'`ì€ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì„¤ì •í•œ ê²ƒì…ë‹ˆë‹¤.\n",
      "íŒŒì¼ ì—†ìŒ - GPTëŠ” ë§ë§Œ í–ˆìŒ\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# íŒŒì¼ ì‚­ì œ\n",
    "if os.path.exists(\"todos.txt\"):\n",
    "    os.remove(\"todos.txt\")\n",
    "\n",
    "# GPTì—ê²Œ íŒŒì¼ ì €ì¥ ìš”ì²­\n",
    "response = llm.invoke(\"todos.txtì— 'íŒŒì´ì¬ ê³µë¶€'ë¥¼ ì¶”ê°€í•´ì¤˜\")\n",
    "print(f\"GPT ë‹µë³€: {response.content}\")\n",
    "\n",
    "# ì‹¤ì œ í™•ì¸\n",
    "if os.path.exists(\"todos.txt\"):\n",
    "    print(\"íŒŒì¼ ìˆìŒ\")\n",
    "else:\n",
    "    print(\"íŒŒì¼ ì—†ìŒ - GPTëŠ” ë§ë§Œ í–ˆìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe836d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e279eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool ì´ë¦„: add_todo\n",
      "Tool ì„¤ëª…: í•  ì¼ì„ todos.txtì— ì¶”ê°€í•©ë‹ˆë‹¤\n",
      "íŒŒì´ì¬ ê³µë¶€ ì¶”ê°€ë¨\n",
      "í•  ì¼:\n",
      "[ ] íŒŒì´ì¬ ê³µë¶€\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step4_define_tools.py\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add_todo(task: str) -> str:\n",
    "    \"\"\"í•  ì¼ì„ todos.txtì— ì¶”ê°€í•©ë‹ˆë‹¤\"\"\"\n",
    "    with open(\"todos.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[ ] {task}\\n\")\n",
    "    return f\"{task} ì¶”ê°€ë¨\"\n",
    "\n",
    "@tool\n",
    "def show_todos() -> str:\n",
    "    \"\"\"í•  ì¼ ëª©ë¡ì„ ë³´ì—¬ì¤ë‹ˆë‹¤\"\"\"\n",
    "    try:\n",
    "        with open(\"todos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            return f\"í•  ì¼:\\n{f.read()}\"\n",
    "    except:\n",
    "        return \"í•  ì¼ ì—†ìŒ\"\n",
    "\n",
    "# Tool í™•ì¸\n",
    "print(f\"Tool ì´ë¦„: {add_todo.name}\")\n",
    "print(f\"Tool ì„¤ëª…: {add_todo.description}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(add_todo.invoke({\"task\": \"íŒŒì´ì¬ ê³µë¶€\"}))\n",
    "print(show_todos.invoke({}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be6acd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ ë³€ìˆ˜: ['agent_scratchpad', 'input', 'tool_names', 'tools']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "ë‹¹ì‹ ì€ í•  ì¼ ê´€ë¦¬ AIì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "{tools}\n",
    "\n",
    "í˜•ì‹:\n",
    "Question: {input}\n",
    "Thought: ìƒê°\n",
    "Action: [{tool_names}]\n",
    "Action Input: ì…ë ¥\n",
    "Observation: ê²°ê³¼\n",
    "...\n",
    "Final Answer: ë‹µë³€\n",
    "\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "print(f\"ì…ë ¥ ë³€ìˆ˜: {prompt.input_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60e9152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in ./venv/lib/python3.12/site-packages (1.0.8)\n",
      "Requirement already satisfied: langchain-core>=0.1 in ./venv/lib/python3.12/site-packages (from langgraph) (1.2.11)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./venv/lib/python3.12/site-packages (from langgraph) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in ./venv/lib/python3.12/site-packages (from langgraph) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langgraph) (0.3.5)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./venv/lib/python3.12/site-packages (from langgraph) (2.12.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./venv/lib/python3.12/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./venv/lib/python3.12/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (0.7.1)\n",
      "Requirement already satisfied: packaging>=23.2.0 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (26.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (9.1.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "760dd8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (1.2.10)\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.12/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai in ./venv/lib/python3.12/site-packages (1.1.9)\n",
      "Requirement already satisfied: langchain-core in ./venv/lib/python3.12/site-packages (1.2.11)\n",
      "Requirement already satisfied: langchain-text-splitters in ./venv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in ./venv/lib/python3.12/site-packages (from langchain) (1.0.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./venv/lib/python3.12/site-packages (from langchain-core) (0.7.1)\n",
      "Requirement already satisfied: packaging>=23.2.0 in ./venv/lib/python3.12/site-packages (from langchain-core) (26.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./venv/lib/python3.12/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core) (9.1.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./venv/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.12/site-packages (from langchain-core) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in ./venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./venv/lib/python3.12/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.0.46)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in ./venv/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in ./venv/lib/python3.12/site-packages (from langchain-openai) (2.17.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./venv/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./venv/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-community langchain-openai langchain-core langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d7ba835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32191/1728993194.py:44: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_app = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘... ---\n",
      "\n",
      "[ìµœì¢… ë‹µë³€]\n",
      "'íŒŒì´ì¬ ê³µë¶€'ê°€ í•  ì¼ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"key.env\")\n",
    "\n",
    "# -------------------------\n",
    "# 1. LLM ì •ì˜\n",
    "# -------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Tools ì •ì˜\n",
    "# -------------------------\n",
    "@tool\n",
    "def add_todo(task: str) -> str:\n",
    "    \"\"\"í•  ì¼ ëª©ë¡ íŒŒì¼(todos.txt)ì— ìƒˆë¡œìš´ í•  ì¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
    "    with open(\"todos.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[ ] {task}\\n\")\n",
    "    return f\"'{task}' ë‚´ìš©ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "@tool\n",
    "def show_todos() -> str:\n",
    "    \"\"\"todos.txt íŒŒì¼ì— ì €ì¥ëœ ëª¨ë“  í•  ì¼ ëª©ë¡ì„ ì½ì–´ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(\"todos.txt\"):\n",
    "            return \"í•  ì¼ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\"\n",
    "        with open(\"todos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            return f\"í˜„ì¬ í•  ì¼ ëª©ë¡:\\n{content}\" if content else \"í•  ì¼ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    except Exception as e:\n",
    "        return f\"íŒŒì¼ ì½ê¸° ì—ëŸ¬: {str(e)}\"\n",
    "\n",
    "tools = [add_todo, show_todos]\n",
    "\n",
    "# -------------------------\n",
    "# 3. Agent ìƒì„±\n",
    "# -------------------------\n",
    "# [ìˆ˜ì •] state_modifier -> prompt ë¡œ ë³€ê²½\n",
    "# (ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì— ë”°ë¼ íŒŒë¼ë¯¸í„° ì´ë¦„ì´ ë‹¤ë¦…ë‹ˆë‹¤)\n",
    "agent_app = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=\"ë‹¹ì‹ ì€ í•  ì¼ ê´€ë¦¬ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì •í™•íˆ ìˆ˜í–‰í•˜ì„¸ìš”.\" \n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 4. ì‹¤í–‰\n",
    "# -------------------------\n",
    "print(\"--- ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘... ---\")\n",
    "\n",
    "# invoke í˜¸ì¶œ (messages ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬)\n",
    "response = agent_app.invoke({\n",
    "    \"messages\": [(\"human\", \"íŒŒì´ì¬ ê³µë¶€ë¥¼ í•  ì¼ì— ì¶”ê°€í•´ì¤˜\")]\n",
    "})\n",
    "\n",
    "# -------------------------\n",
    "# 5. ê²°ê³¼ ì¶œë ¥\n",
    "# -------------------------\n",
    "print(\"\\n[ìµœì¢… ë‹µë³€]\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6063b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ddgs\n",
      "  Downloading ddgs-9.10.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in ./venv/lib/python3.12/site-packages (from ddgs) (8.3.1)\n",
      "Collecting primp>=0.15.0 (from ddgs)\n",
      "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting lxml>=4.9.4 (from ddgs)\n",
      "  Using cached lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: httpx>=0.28.1 in ./venv/lib/python3.12/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
      "Collecting fake-useragent>=2.2.0 (from ddgs)\n",
      "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
      "Collecting brotli (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading brotli-1.2.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading h2-4.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in ./venv/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
      "Downloading ddgs-9.10.0-py3-none-any.whl (40 kB)\n",
      "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
      "Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading brotli-1.2.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: brotli, socksio, primp, lxml, hyperframe, hpack, fake-useragent, h2, ddgs\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9/9\u001b[0m [ddgs][32m5/9\u001b[0m [hpack]\n",
      "\u001b[1A\u001b[2KSuccessfully installed brotli-1.2.0 ddgs-9.10.0 fake-useragent-2.2.0 h2-4.3.0 hpack-4.1.0 hyperframe-6.1.0 lxml-6.0.2 primp-0.15.0 socksio-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ddgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14b094fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ìƒ‰ì–´: 2025ë…„ í˜„ëŒ€ìë™ì°¨ ë¯¸êµ­ ì‹œì¥ ì „ë§\n",
      "\n",
      "[ê²°ê³¼ 1]\n",
      "ì œëª©: KRVIP ë¡œê·¸ì¸ ì—ì„œì˜ ìœ„í—˜ ìš”ì†Œì™€ ì˜ˆë°© ì „ëµ - 2025ë…„ ìµœì‹  ê°€ì´ë“œ\n",
      "ë‚´ìš©: ë¯¸êµ­ ì „ê¸°ì°¨ í…ŒìŠ¬ë¼ê°€ ì¡°ë§Œê°„ êµ­ë‚´ì— 6ì¸ìŠ¹ ì „ê¸° ìŠ¤í¬ì¸ ìœ í‹¸ë¦¬í‹°(SUV) ì°¨ì¢…ì¸ 'ëª¨ë¸YL'ì„ ì„ ë³´ì´ë©´ì„œ êµ­ë‚´ íŒ¨ë°€ë¦¬ì¹´ ì‹œì¥ì— ë„ì „ì¥ì„ ë‚´ë°€ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤....\n",
      "------------------------------------------------------------\n",
      "[ê²°ê³¼ 2]\n",
      "ì œëª©: ê¸€ë¡œë²Œì˜¤í† ë‰´ìŠ¤ Global Auto News (@global_auto_news) - Instagram\n",
      "ë‚´ìš©: ë¶ë¯¸ ìë™ì°¨ ì „ë¬¸ ê¸°ì 50ëª…ì´ 1ë…„ê°„ í…ŒìŠ¤íŠ¸í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ì™œ í•˜ì´ë¸Œë¦¬ë“œ SUVê°€ ìµœì¢…ìŠ¹ìê°€ ë˜ì—ˆì„ê¹Œìš”? ë¯¸êµ­ ì‹œì¥ì˜ ë³€í™” 2025ë…„ 2ë¶„ê¸° í•˜ì´ë¸Œë¦¬ë“œ íŒë§¤ 36% ê¸‰ì¦ ......\n",
      "------------------------------------------------------------\n",
      "[ê²°ê³¼ 3]\n",
      "ì œëª©: [PDF] Future Trend and New Engine Technologies to Meet Emission ...\n",
      "ë‚´ìš©: â– ì¤‘êµ­ê³¼ ë¯¸êµ­ì€ ì„¸ê³„ ì „ê¸°ì°¨ ì‹œì¥ì„ ì„ ë„í•˜ê³  ìˆìŒ. â– ì¤‘êµ­ì€ ì‹  ì—ë„ˆì§€ ... Source : í˜„ëŒ€ìë™ì°¨ ìˆ˜ì†Œ ì—°ë£Œì „ì§€, NH íˆ¬ìì¦ê¶Œ ë¦¬ì„œì¹˜ ë³¸ë¶€. (DOE, 2018). FCEV ......\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ddgs import DDGS\n",
    "\n",
    "query = \"2025ë…„ í˜„ëŒ€ìë™ì°¨ ë¯¸êµ­ ì‹œì¥ ì „ë§\"\n",
    "\n",
    "print(f\"ê²€ìƒ‰ì–´: {query}\\n\")\n",
    "\n",
    "try:\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=3)\n",
    "        for i, r in enumerate(results, 1):\n",
    "            print(f\"[ê²°ê³¼ {i}]\")\n",
    "            print(f\"ì œëª©: {r['title']}\")\n",
    "            print(f\"ë‚´ìš©: {r['body'][:200]}...\")\n",
    "            print(\"-\" * 60)\n",
    "except Exception as e:\n",
    "    print(f\"ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b8f175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›¹ ê²€ìƒ‰ ë´‡ (quitë¡œ ì¢…ë£Œ)\n",
      "\n",
      "ë°œë Œíƒ€ì¸ë°ì´ ì„ ë¬¼ë¡œëŠ” ì–´ë–¤ ìŠ¤íƒ€ì¼ì´ë‚˜ ì·¨í–¥ì„ ê³ ë ¤í•˜ê³  ê³„ì‹ ê°€ìš”? ì˜ˆë¥¼ ë“¤ì–´, ë¡œë§¨í‹±í•œ ì„ ë¬¼, ì‹¤ìš©ì ì¸ ì„ ë¬¼, í˜¹ì€ íŠ¹ë³„í•œ ê²½í—˜ì„ ì„ ë¬¼í•˜ê³  ì‹¶ì€ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë” ë§ì¶¤í˜• ì¶”ì²œì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ì•„ë‹ˆë©´ ì„ ë¬¼ ë°›ì„ ë¶„ì˜ ë‚˜ì´, ì„±ë³„, ì·¨ë¯¸ ë“±ë„ ì•Œë ¤ì£¼ì‹œë©´ ë„ì›€ì´ ë©ë‹ˆë‹¤!\n",
      "\n",
      "ì´ˆì½œë¦¿ì„ ì œì™¸í•˜ê³  ìƒ‰ë‹¤ë¥¸ ê°„ì‹ì´ë‚˜ ë””ì €íŠ¸ë¥¼ ì°¾ìœ¼ì‹œëŠ” ê±´ê°€ìš”? ì•„ë‹ˆë©´ ìƒ‰ë‹¤ë¥¸ ì„ ë¬¼ì´ë‚˜ ì•„ì´ë””ì–´ë¥¼ ì›í•˜ì‹œëŠ” ê±´ê°€ìš”? ì–´ë–¤ ì¢…ë¥˜ì˜ ìƒ‰ë‹¤ë¥¸ ê²ƒì„ ì›í•˜ì‹œëŠ”ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ë„ì›€ì´ ë  ê²ƒ ê°™ì•„ìš”!\n",
      "\n",
      "ê°„ì‹ì„ ì œì™¸í•œ ì–´ë–¤ ë‚´ìš©ì„ ì›í•˜ì‹œëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‹ì‚¬ ë©”ë‰´, ìš´ë™ ê³„íš, ê³µë¶€ ë°©ë²• ë“± ì–´ë–¤ ì£¼ì œì— ëŒ€í•´ ê°„ì‹ì„ ì œì™¸í•˜ê³  ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?\n",
      "\n",
      "ì—¬ìì¹œêµ¬ ìƒì¼ ì„ ë¬¼ë¡œ ë°°ìŠ¤ ë‚šì‹œë¥¼ ì‹œë„í•˜ëŠ” ì˜ìƒì´ TikTokì— ì˜¬ë¼ì™”ìœ¼ë©°, ì‹¤ì œë¡œ ë°°ìŠ¤ë¥¼ ì¡ëŠ” ì¥ë©´ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 20ëŒ€ê°€ ì¢‹ì•„í•˜ëŠ” ì„ ë¬¼ ì•„ì´ë””ì–´ë„ TikTokì—ì„œ ì†Œê°œë˜ê³  ìˆëŠ”ë°, ê¸°ë…ì¼ì´ë‚˜ ìƒì¼ì— ì í•©í•œ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ê°€ ì œê³µë©ë‹ˆë‹¤. í•œí¸, ì¸ìŠ¤íƒ€ê·¸ë¨ì—ì„œëŠ” Bosch ìœ ë¦¬ê±°ìš¸ ì²­ì†Œê¸° ë“± ì§‘ì•ˆì¼ì„ í¸ë¦¬í•˜ê²Œ í•´ì£¼ëŠ” ì‹ ê¸°í•œ ê°€ì „ì œí’ˆë“¤ì´ ì†Œê°œë˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# example1_web_search.py\n",
    "\"\"\"\n",
    "[ê¸°ëŠ¥] ì›¹ ê²€ìƒ‰ + GPT ìš”ì•½\n",
    "- ddgsë¡œ ì‹¤ì‹œê°„ ê²€ìƒ‰\n",
    "- ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•œê¸€ë¡œ ìš”ì•½\n",
    "\"\"\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from ddgs import DDGS\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤\"\"\"\n",
    "    try:\n",
    "        results = []\n",
    "        with DDGS() as ddgs:\n",
    "            for r in ddgs.text(query, max_results=3):\n",
    "                results.append(f\"{r['title']}: {r['body']}\")\n",
    "        return \"\\n\\n\".join(results) if results else \"ê²°ê³¼ ì—†ìŒ\"\n",
    "    except Exception as e:\n",
    "        return f\"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}\"\n",
    "\n",
    "tools = [web_search]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"ì›¹ ê²€ìƒ‰ ë´‡ (quitë¡œ ì¢…ë£Œ)\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\n> \").strip()\n",
    "\n",
    "    if user_input.lower() in ['quit', 'exit', 'q', 'ì¢…ë£Œ', 'ë']:\n",
    "        break\n",
    "\n",
    "    if not user_input:\n",
    "        continue\n",
    "\n",
    "    # LLM í˜¸ì¶œ\n",
    "    messages = [{\"role\": \"user\", \"content\": user_input}]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    # ë„êµ¬ ì‹¤í–‰\n",
    "    if response.tool_calls:\n",
    "        search_result = web_search.invoke(response.tool_calls[0][\"args\"])\n",
    "\n",
    "        # ìš”ì•½\n",
    "        summary = llm.invoke(f\"ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•œê¸€ë¡œ 3-4ë¬¸ì¥ ìš”ì•½:\\n{search_result[:2000]}\")\n",
    "        print(f\"\\n{summary.content}\")\n",
    "    else:\n",
    "        print(f\"\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8821b2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-11 14:08:30.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.685 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.689 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.692 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.692 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.701 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-11 14:08:30.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •\n",
    "load_dotenv(\"key.env\")\n",
    "\n",
    "# 2. ë„êµ¬(Tool) ì •ì˜: ì„±ê· ê´€ëŒ€ ê³µì§€ì‚¬í•­ í¬ë¡¤ëŸ¬\n",
    "@tool\n",
    "def fetch_skku_notices(keyword: str) -> str:\n",
    "    \"\"\"\n",
    "    ì„±ê· ê´€ëŒ€í•™êµ í•™ë¶€ ê³µì§€ì‚¬í•­ ì‚¬ì´íŠ¸ì—ì„œ í‚¤ì›Œë“œë¡œ ê³µì§€ì‚¬í•­ì„ ê²€ìƒ‰í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    'ì¥í•™ê¸ˆ', 'ë“±ë¡ê¸ˆ', 'ìˆ˜ê°•ì‹ ì²­' ë“± í•™êµ ì†Œì‹ì´ ê¶ê¸ˆí•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    # ì„±ê· ê´€ëŒ€ ê³µì§€ì‚¬í•­ ê²€ìƒ‰ URL (í‚¤ì›Œë“œ íŒŒë¼ë¯¸í„° í¬í•¨)\n",
    "    url = f\"https://www.skku.edu/skku/campus/skk_comm/notice01.do?mode=list&srSearchVal={keyword}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # ê³µì§€ì‚¬í•­ ëª©ë¡ ì¶”ì¶œ (ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¥¸ ì„ íƒì ì„¤ì •)\n",
    "        notice_list = soup.select(\".board-list-wrap table tbody tr\")\n",
    "        \n",
    "        if not notice_list:\n",
    "            return f\"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        results = []\n",
    "        for item in notice_list[:10]:  # ìµœì‹  10ê°œë§Œ ì¶”ì¶œ\n",
    "            title_tag = item.select_one(\".td-subject a\")\n",
    "            date_tag = item.select_one(\".td-date\")\n",
    "            \n",
    "            if title_tag:\n",
    "                title = title_tag.get_text(strip=True)\n",
    "                link = \"https://www.skku.edu/skku/campus/skk_comm/notice01.do\" + title_tag['href']\n",
    "                date = date_tag.get_text(strip=True) if date_tag else \"ë‚ ì§œ ë¶ˆëª…\"\n",
    "                results.append(f\"ğŸ“Œ ì œëª©: {title}\\nğŸ“… ë‚ ì§œ: {date}\\nğŸ”— ë§í¬: {link}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(results)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"ê³µì§€ì‚¬í•­ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "# 3. Agent ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "tools = [fetch_skku_notices]\n",
    "\n",
    "# 4. Streamlit UI\n",
    "st.set_page_config(page_title=\"SKKU ê³µì§€ ë¹„ì„œ\", page_icon=\"ğŸ«\")\n",
    "st.title(\"ğŸ« ì„±ê· ê´€ëŒ€ ì‹¤ì‹œê°„ ê³µì§€ì‚¬í•­ ë¹„ì„œ\")\n",
    "\n",
    "# ì‚¬ì´ë“œë°”: ë‚´ ì •ë³´(í•„í„°ë§ìš©)\n",
    "with st.sidebar:\n",
    "    st.header(\"ğŸ‘¤ ë‚˜ì˜ í”„ë¡œí•„\")\n",
    "    user_info = st.text_area(\"ë‚˜ì˜ ì¡°ê±´ (í•™ê³¼, í•™ë…„, ê´€ì‹¬ë¶„ì•¼)\", \n",
    "                            value=\"ì»´í“¨í„°ê³µí•™ê³¼ 3í•™ë…„, ì„±ì  3.8, ì¥í•™ê¸ˆì— ê´€ì‹¬ ë§ìŒ.\")\n",
    "\n",
    "# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"ì–´ë–¤ ê³µì§€ì‚¬í•­ì„ ì°¾ì•„ë“œë¦´ê¹Œìš”? (ì˜ˆ: ì¥í•™ê¸ˆ, ì¡¸ì—…, ì¸í„´)\"}]\n",
    "\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "if prompt := st.chat_input(\"í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "\n",
    "    # ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "    # ì‚¬ìš©ìì˜ í”„ë¡œí•„ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…í•˜ì—¬ ë§ì¶¤í˜• ìš”ì•½ì„ ìœ ë„í•¨\n",
    "    prompt_template = f\"\"\"\n",
    "    ë‹¹ì‹ ì€ ì„±ê· ê´€ëŒ€í•™êµ í•™ìƒì„ ë•ëŠ” 'SKKU ê³µì§€ ë¹„ì„œ'ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    [í•™ìƒ ì •ë³´]\n",
    "    {user_info}\n",
    "    \n",
    "    [ì„ë¬´]\n",
    "    1. ì‚¬ìš©ìê°€ ë¬»ëŠ” í‚¤ì›Œë“œë¡œ 'fetch_skku_notices' ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ê³µì§€ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.\n",
    "    2. ê²€ìƒ‰ëœ ê³µì§€ ë‚´ìš©ì´ [í•™ìƒ ì •ë³´]ì— í•´ë‹¹ë˜ëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”.\n",
    "    3. ì§€ì› ê°€ëŠ¥í•œ ì¥í•™ê¸ˆì´ë‚˜ ìœ ìš©í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ê°•ì¡°í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "    4. ì¹œì ˆí•˜ê²Œ í•™êµ ì„ ë°°ì²˜ëŸ¼ ë‹µë³€í•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    "\n",
    "    agent = create_react_agent(model=llm, tools=tools, prompt=prompt_template)\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"í•™êµ í™ˆí˜ì´ì§€ì—ì„œ ê³µì§€ë¥¼ ì°¾ëŠ” ì¤‘...\"):\n",
    "            response = agent.invoke({\"messages\": [HumanMessage(content=prompt)]})\n",
    "            final_answer = response[\"messages\"][-1].content\n",
    "            st.markdown(final_answer)\n",
    "\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": final_answer})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
